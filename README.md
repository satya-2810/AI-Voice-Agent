# MURF AI-Powered Voice Agent

An interactive AI-powered voice assistant that converts speech to text (STT), processes it with a Large Language Model (LLM), and responds with natural text-to-speech (TTS).  
The project integrates Murf AI for voice synthesis, AssemblyAI for transcription, and Google's Gemini API for intelligent responses.

## ðŸš€ Features

- ðŸŽ™ **Speech to Text (STT)**: Converts voice input into accurate text using AssemblyAI.
- ðŸ§  **Conversational Memory**: Maintains chat history for contextual responses.
- ðŸ¤– **LLM Integration**: Uses Gemini API for intelligent replies.
- ðŸ”Š **Text to Speech (TTS)**: Converts AI responses into natural-sounding audio using Murf AI.
- ðŸ’¾ **Session Management**: Session IDs to store conversation context.
- ðŸŽ¨ **Modern UI**: Glassmorphism-inspired front-end design.
- ðŸ“‚ **Multi-format Input Support**: Can handle audio inputs (WAV) and return audio or fallback responses.

## ðŸ›  Tech Stack

**Frontend:**

- HTML5, CSS3 (Glassmorphism styling)
- JavaScript (MediaRecorder API)

**Backend:**

- Python (FastAPI)
- Murf AI API (TTS)
- AssemblyAI API (STT)
- Google Gemini API (LLM)

**Other Tools:**

- FormData for file transfer
- Fetch API for backend communication

## ðŸ“‚ Project Structure

```plaintext
project-root/
|â”€â”€ assets/
â”‚â”€â”€ static/
â”‚   â”œâ”€â”€ script.js          # Frontend JS logic (recording, sending audio, handling responses)
â”‚   â”œâ”€â”€ style.css          # Frontend styles
â”‚â”€â”€ templates/
â”‚   â”œâ”€â”€ index.html         # Main UI
â”‚â”€â”€ uploads/               # Uploaded audio files
â”‚â”€â”€ app.py                 # FastAPI backend
â”‚â”€â”€ requirements.txt       # Python dependencies
â”‚â”€â”€ .env                   # Environment variables
â”‚â”€â”€ venv/                  # Virtual environment
```

## ðŸ— Architecture

```mermaid
graph TD;
    User[ðŸŽ¤ User Speaks] -->|Audio Input| BrowserJS[Frontend JS]
    BrowserJS -->|Send Audio| FastAPI[FastAPI Backend]
    FastAPI -->|STT| AssemblyAI[AssemblyAI API]
    AssemblyAI -->|Transcript| LLM[Gemini API]
    LLM -->|Response Text| MurfAI[Murf AI API]
    MurfAI -->|Audio Response| BrowserJS
    BrowserJS -->|Play Audio| User
```

## âš™ Setup Instructions

1. **Clone the repository**

   ```bash
   git clone <repo-url>
   cd <repo-folder>
   ```

2. **Create a virtual environment & activate it**

   ```bash
   python -m venv venv
   source venv\Scripts\activate
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Create a `.env` file**

   ```env
   MURF_API_KEY=your_murf_api_key
   ASSEMBLYAI_API_KEY=your_assemblyai_api_key
   GEMINI_API_KEY=your_gemini_api_key
   ```

5. **Run the server**

   ```bash
   uvicorn app:app --reload
   ```

6. **Open the UI**
   - Visit `http://127.0.0.1:8000` in your browser.

## ðŸ“¸ Screenshots

![Architecture of the project](assets/architecture_diagram.png "Architecture")
![UI interface](assets/ui_interface.png "Interface")

---

ðŸ’¡ **Pro Tip**: Keep your API keys safe and never commit `.env` to version control.
